\section{Application-Specific Functions}\label{app_func}
%III.	Application Functions
%	a.	Resource Value Functions
%		i.	Structure
%		ii.	Model Building Approach
%			1.	Who measures the data?
%	b.	Penalty Functions
%		i.	Where do the deadlines come from?
%		ii.	How do we set the slopes?
%	c.	Power Model


In this section, we describe the design of each of \pacora's application-specific functions in more detail.

\subsection*{Response Time Functions}

A response time function describes an application's performance based on its resource assignments.  These functions capture information about the value of a particular resource type to an application.  How well an application scales on a particular resource is high depend on the specific application and how it was written along with performance properties of the resources, which is why we believe it is necessary to collection application-specific data for each application. Without information of this type, it would be difficult for any resource allocation system informed decisions.  Thus forcing the system to be entirely reactive and most likely require a complex set of heuristics.  

While it might be possible to model response times by recording past values and interpolating among them, this idea has serious shortcomings:
\begin{itemize}
\item The size of the multidimensional response time function tables will be large;
\item Interpolation in many dimensions is computationally expensive;
\item The measurements will be noisy and require smoothing;
\item Convexity in the resources may be violated;
\item Gradient estimation will be difficult.
\end{itemize}
Alternatively, the resource manager could allocate a modest amount of a resource and measure the change in response time; however this is a difficult way to traverse a multidimensional space.

Instead of these, \pacora maintains a parameterized analytic response time model with the partial derivatives evaluated from the model \emph{a priori}. Application responsiveness is highly nonlinear for an increasing variety of applications like streaming media or gaming, thus requiring many data points to represent the response times without a model. Using models each application can be described in a small number of parameters.  Additionally models can be built from few data points and naturally smooth out noisy data. The resource gradient can be easily calculated which is essential for \pacora to solve the optimization problem efficiently.  

\pacora models response times by functions that are convex by construction.  The specific function chosen for \pacora is shown in Equation~\ref{rtf_eq}.  In this equation, the response time is be modeled as a weighted sum of component terms, one per resource, where each term $w_r/a_r$ is the amount of work $w_r \geq 0$ divided by $a_r$, the allocation of that resource\cite{Snav}. For example, one term might model the number of instructions executed divided by total processor MIPS, another might model storage accesses divided by storage bandwidth allocation and so forth. Additional terms represent the interactions between resources.
Such models are automatically convex in the allocations because $1/a$ is convex for positive $a$ and because a positively-weighted sum of convex functions is convex.  

We choose this specific function because initial application studies we found it models response time behavior accurately enough 
and we found in our initial experiments that a 


It is obviously important to guarantee the positivity of the resource allocations.
This can be enforced as the allocations are selected during penalty optimization,
or the response time model can be made to return $\infty$ if any allocation is less than or equal to zero.
This latter idea preserves the convexity of the model and extends its domain to all of $\Re^n$.



The gradient $\nabla\tau$ is needed by the penalty optimization algorithm.
Since $\tau$ is analytic, generic, and symbolically differentiable
it is a simple matter to compute the gradient of $\tau$ once the model is defined.

\fix{Why convexity is reasonable}
To guarantee the objective function is convex, the response time must be also;
this is a plausible requirement akin to the proverbial ``Law of Diminishing Returns''.
\fix{changing apps}
\fix{dynamic compilation}
\fix{phases}
Response time will commonly vary with time as a process changes phase and makes better or worse use of its resources.
\fix{non-determinism}
Asynchrony and latency tolerance may make response time components overlap partly or fully;
if the latter, then the maximum of the terms might be more appropriate than their sum.
The result will still be convex, though, as will any other norm including the 2-norm,
\emph{i.e.} the square root of the sum of the squares.
This last variation could be viewed as a ``partially overlapped'' compromise between
the 1-norm (sum) describing no overlap and the $\infty$-norm (maximum) describing full overlap.

\fix{non-convex behavior}
There are examples of response time versus resource behavior that violate convexity.  One such example sometimes occurs in memory allocation, where ``plateaus'' can sometimes be seen as in Figure~\ref{f:plat}.
\begin{figure}[b]
\parbox{1.6in}{
\includegraphics*{Plateau1.eps}
\caption{\label{f:plat}Response time function with some resource ``plateaus''.}
}
\hspace{\fill}
\parbox{1.6in}{
\includegraphics*{Plateau2.eps}
\caption{\label{f:plateffect}Net effect of the resource plateaus on the process penalty.}
}
\end{figure}
Such plateaus are typically caused by algorithm adaptations within the process to accommodate variable resource availability.  The response time is really the \emph{minimum} of several convex functions depending on allocation and the point-wise minimum that the process implements fails to preserve convexity.  The effect of the plateaus will be a non-convex penalty as shown in Figure~\ref{f:plateffect} and multiple extrema in the optimization problem will be a likely result.

There are several ways to avoid this problem.  One is based on the observation that such response time functions will at least be \emph{quasiconvex}.  Another idea is to use additional constraints to explore convex sub-domains of $\tau$. For example,the affine constraint $a_{p,r} - \mu \leq 0$ excludes process $p$ from any assignment of resource $r$ exceeding $\mu$.  Similarly, $\mu - a_{p,r} \leq 0$ excludes the opposite possibility.
A binary (or even linear)search of such sub-domains could be used to find the optimal value.
\fix{appendix ptr}

There are several possible ways to collect the response time data for applications. A user-level runtime scheduler that schedules work internal to the process may be a good source of data or the operating system could measure progress using performance counters.  In our implementation applications report their own measured values: however, this solution was chosen simply as a way to test the validity of the concept.  In a production operating system, it may not be the best approach because it requires trusting applications not to lie about their performance.  In a datacenter environment this may be less of a concern. 

There are also many different possible times response time functions could be created.  RTFs could be created in advance and distributed with the application. In the case of app stores this approach could make lot of sense since most app stores only cater to a limited number of platforms. Data could also be crowd sourced and the RTFs built in the cloud, which has the advantage making it easy to collect a diverse set of 

\subsection*{Penalty Functions}

\fix{Purpose}
Penalty functions  are generically defined as members of a family of such functions
so that user preferences for a process $p$ (elided in the discussion below)
can be implemented by assigning values to a few well-understood parameters.
\fix{Model Choice}
In traditional systems, responsiveness has been described by a single value (usually called a \emph{priority}) associated with a thread of computation and adjusted within the operating system by a variety of ad-hoc mechanisms.   Priority approaches have no mechanism to understand deadlines or the resources required to meet a deadline and as such must run the highest priority applications as fast as possible on all the resources requested. 

for these real-time applications, performance is measured as sufficient if the deadline is met and insufficient otherwise.

To guarantee it is convex and non-decreasing, $s$ must be non-negative.
The response time $\tau$  is of course non-negative,
and it may be sensible (if not strictly necessary) to convene that $d$ is also.
A response time constrained process has a marked change in slope, namely from 0 to $s$, at the point $\tau= d$.
In the most extreme case $s = \infty$ (implying infinite penalty for the system as a whole when $\tau > d$).  ``Softer'' requirements will doubtless be the rule.
For processes without response time constraints one can set $d = 0$.
This defines linear behavior with $s$ as the rate of penalty increase with response time.

The gradient of process penalty with respect to its resource allocations is useful in controlling the optimization algorithm.
By the chain rule, $\partial\pi/\partial a_r = \partial\pi/\partial\tau\cdot\partial\tau/\partial a_r$.
The first term is well-defined but discontinuous at $\tau = d$ with
$\partial\pi/\partial\tau = \mbox{ if } (\tau - d) \leq 0 \mbox{ then } 0 \mbox{ else } s$.
The problem of estimating the partial derivatives $\partial\tau/\partial a_r$ is dealt with below.
\fix{How to Set}
In a client operating system, the instantaneous management of penalty function modifications
should be highly automated by the system to avoid unduly burdening the user.
\fix{dynamic adjustments}
As a process grows or diminishes in importance, its penalty function can be modified accordingly.

\subsection*{Power and Battery Energy}
In order to control power and energy of the system, we use an artificial application named Application 0 which receives all resources not allocated to other applications. Application 0's response time function is similar to the other applications' response time functions.  The function inputs are resource allocations just as with the other applications.  However, the function output is system power rather than response time.   To create the RTF, system power can be measured directly from on-chip energy counters in systems that they are available or from a power meter.  These models can be built in advance, durning a training phase or online while the system runs, just as with the application RTFs.  Alternatively, the model could be part of the operating system platform-specific information. 

Although system power may not be entirely convex in reality, approximating it to be convex is reasonable because the convex model still captures the general behavior that leaving a resource idle should save some or no power.  As a result, Application 0 still fills its purpose of preventing applications using additional resources that have low performance/power ratios.  

The penalty function can be adjusted to represent how important saving power and energy is in the current operating scenario.  For example, if a mobile device is plugged in to a charger than perhaps the penalty slope should be set very low.  However if the device is unplugged the penalty function could be changed to have a deadline and then an steep slope which represents creating a power cap for the system.  In this way the deadline and slope could be set to help control the minimum number of hours the battery will last.

