\section{\pacora Architecture}
\fix{add pacora system figure - math}

%II.	System Architecture
%		i.	Application Specific
%		ii.	Resources Matter
%		iii.	Measurement
%		iv.	Optimization
%	a.	Convex by construction
%		i.	Fairly representative of the actual system
%			1.	(Systems should be more convex)
%		ii.	Low Overhead
%	b.	Explanation of resources
%	c.	Performance Models Built Online
%		i.	Explanation of performance
%		ii.	When does it run?
%	d.	Penalty functions
%	e.	Dynamic Optimization
%		i.	When does it run?


%\pacora, which stands for Performance-Aware Convex Optimization for Resource Allocation, is a framework designed to determine the proper amount of each resource type to assign to each application.  For our purposes an application is the entity to which the operating system allocates resources: it can viewed as a complete application (\emph{e.g.,} a video player) or a component of an application (\emph{e.g.,} a music synthesizer) or a process (\emph{e.g.,} indexing).  

\pacora is a framework designed to determine the proper amount of each resource type to assign to each application.  For our purposes an application is the entity to which the system allocates resources: it can viewed as a complete application (\emph{e.g.,} a video player) or a component of an application (\emph{e.g.,} a music synthesizer) or a process (\emph{e.g.,} indexing) for operating systems, jobs for warehouse-scale computing, and distributed applications in distributed embedded systems. 

In our client system, resources are anything that the system can provide QoS on in hardware or software: specifically we use cpus, network bandwidth, cache ways, and memory pages in our system.  However, other resources could easily be added as well assuming they have QoS enforcement mechanisms.  The other scenarios would have resources that perform similar functions (compute, network, capacity), but at a different scale. For warehouse-scale computing resources are more likely to be different types of nodes, network bandwidth, and storage, and distributed embedded systems would include compute devices, link bandwidth, and memory. 
 
\pacora is designed to work in systems with hierarchical scheduling.  In a client system, this design just looks like classic two-level scheduling.  \pacora makes allocation decisions about resources (\emph{e.g.,} cores and memory pages), and micro-management of the resources within an application is left to user-level runtimes such as User Mode Scheduling in Windows\cite{um_sched} or Lithe\cite{lithe} and memory managers.  In a cloud environment, \pacora allocates resources (\emph{e.g.,} nodes and storage) to jobs, and scheduling is left to other entities such as the MapReduce framework\cite{mapreduce} or the operating system on the node.  Separating resource allocation from scheduling enables the use of application-specific scheduling policies, which have the potential to easier to design and more efficient than a general-purpose scheduler that has to work for everything.   This approach leaves the system to focus on the problem of \emph{how many} of each resource type of assign to each application. 

\fix{add video scenario here?}
 
\pacora takes a different approach to resource allocation than traditional systems: measurement, application-specific, resources matter, optimization 


\pacora formulates resource allocation as an optimization problem built from two types of application-specific functions: a Response Time Function and a Penalty function. The Response Time Function represents the measured performance of the application on different resources.  The Penalty Function represents the user-level goals for the application (i.e., the deadline and how important it is to make that deadline). The following sections describe each of the functions and the optimization construction.

\subsection*{Response Time Functions}

Response Time Functions are built from data on 

 the \emph{response time},
    is an appropriate measure of the performance of the process.
    For example,the response time of a process might be one of these:
    \begin{itemize}[noitemsep]
    \item The time from a mouse click to its result;
    \item The time from a service request to its response;
    \item The time from job launch to job completion;
    \item The time to execute a specified amount of work.
    \end{itemize}
The response time of a process is a function of the allocated resources and is predicted from its history of resource usage.

The assumptions underlying strategies of this sort no longer hold, especially for emerging client systems.  The value of application responsiveness is highly nonlinear for an increasing variety of applications like streaming media or gaming;    

\subsection*{Penalty Functions}


The penalty of a process is a function rather than a single value
    and the argument of each penalty function
    
    
In tradition systems, responsiveness has been described by a single value (usually called a \emph{priority}) associated with a thread of computation and adjusted within the operating system by a variety of ad-hoc mechanisms.   Priority approaches have no mechanism to understand deadlines or the resources required to meet a deadline and as such must run the highest priority applications as fast as possible on all the resources requested. 

for these real-time applications, performance is measured as sufficient if the deadline is met and insufficient otherwise.
    
    
\subsection*{Idle Process}    

\subsection*{Resource Allocation As Optimization}
\pacora formulates resource allocation as an optimization problem 


A succinct mathematical characterization of this resource allocation scheme is the following:
\begin{eqnarray*}
& \makebox[1in][r]{Minimize}   & \sum_{p\epsilon P} {\pi_p(\tau_p(a_{p,1}\ldots a_{p,n}))}  \\
& \makebox[1in][r]{Subject to} & \sum_{p\epsilon P} a_{p,r} \leq A_r, r = 1,\ldots n        \\
& \makebox[1in][r]{and}        & a_{p,r} \geq 0
\end{eqnarray*}
Here $\pi_p$ is the penalty function for process $p$,
$\tau_p$ is its response time function,
$a_{p,r}$ is the allocation of resource $r$ to process $p$,
and $A_r$ is the total amount of resource $r$ available.


\subsection*{Convex Optimization}
If the penalty functions, response time functions, and resource constraints were arbitrarily,
little could be done to optimize the total penalty beyond searching at random for the best allocation.
However, if resource management can be framed as a \emph{convex optimization problem}\cite{BoVa},
two benefits will accrue: an optimal solution will exist without multiple local extrema and
fast, incremental solutions will become feasible.

A constrained optimization problem will be convex if both the objective function to be minimized
and the constraint functions that define its feasible solutions are convex functions.
A function $f$ is convex if its domain is a convex set and
$F(\theta x + (1-\theta)y) \leq \theta F(x) + (1-\theta)F(y)$
for all $\theta$ between 0 and 1.
A set is convex if for any two points $x$ and $y$ in the set, the point
$\theta x + (1-\theta)y$
is also in the set for all $\theta$ between 0 and 1.
If $F$ is differentiable, it is convex if its domain is an open convex set and
$F(y) \geq F(x) + \nabla F^T(y-x)$ where $\nabla F$ is the gradient of $F$.
Put another way, $F$ is convex if its first-order Taylor approximations
are always global underestimates of its true value.

A convex optimization problem is one that can be expressed in this form:
\begin{eqnarray*}
& \makebox[1in][r]{Minimize}   & f_0(x_1,\ldots x_m)                              \\
& \makebox[1in][r]{Subject to} & f_i(x_1,\ldots f_m) \leq 0, i = 1,\ldots k        \\
& \makebox[1in][r]{where}      & \forall i \quad f_i:\Re^m \rightarrow \Re \mbox{ is convex.}
\end{eqnarray*}
A few more facts about convex functions will be useful in what follows.
First, a \emph{concave} function is one whose negative is convex.
Maximization of a concave function is equivalent to minimization of its convex negative.
An affine function, one whose graph is a straight line in two dimensions or a hyperplane in n dimensions,
is both convex and concave.  A non-negative weighted sum or point-wise maximum (minimum) of convex (concave) functions is convex (concave), as is either kind of function composed with an affine function.  The composition of a convex non-decreasing (concave non-increasing) scalar function with a convex function remains convex (concave).

As a consequence, the resource management problem posed above can be transformed into a convex optimization problem in the $m = |P|\cdot n$ variables $a_{p,r}$ as long as the penalty functions $\pi_p$ are convex non-decreasing and the response time functions $\tau_p$ are convex.
Note that the resource constraints are all affine and can be rewritten as
$\sum_{p\epsilon P} a_{p,r} - A_r \leq 0$ and $-a_{p,r} \leq 0$.

\subsection*{Resources}

%Partitionable resources include CPU cores, pages in memory, and
%guaranteed fractional services from other cells (\eg a throughput
%reservation of 150~Mbps from the network service).  They may also
%include cache slices, portions of memory bandwidth, and fractions of the
%energy budget, when hardware support is available
%(\eg~\cite{akesson07,lee08memqos,paolieri09,sanchez11}).
