\section{Introduction}

%I.	Introduction
%	a.	New World of Computing – Client and Cloud
%		i.	Media and Interactive 
%			1.	User experience matters!
%		ii.	Collection of Services
%			1.	On the Client
%			2.	In the Cloud
%		iii.	Developed by domain experts
%			1.	Efficiency (i.e., energy) is still important
%		iv.	Challenge: How do I efficiently guarantee interactivity on my multicore device when it’s running a set of apps?
%	b.	Why tradition solutions don’t work
%	c.	PACORA
%		i.	Application Specific
%		ii.	Resources Matter
%		iii.	Measurement
%		iv.	Optimization


Users have an insatiable appetite for responsive user interfaces and high-quality multimedia with stringent real-time guarantees on their multicore devices, and they expect better performance or responsiveness as the core count increases. Meeting these expectations requires not only parallelizing client applications but striking the right balance of resources among competing software components.  Additionally, modern applications frequently extend into the cloud, requiring responsiveness and performance predictability on a global scale, which adds complexity.

Ideally, applications with strict performance requirements should be given just enough system resources (\emph{e.g.,} processor cores, cache slices, memory pages, various kinds of bandwidth) to meet these requirements consistently, without unnecessarily siphoning resources from other applications. However, executing multiple parallel, real-time applications while satisfying  \emph{Quality-of-Service} (QoS) requirements is a complex optimization problem.  

Consequently, predictability has traditionally been obtained at a significant expense by designing for the worst case and over-provisioning.  Evidence of this behavior can be found in current mobile and cloud systems.  In order to preserve responsiveness and battery life,  some mobile systems have gone so far as to limit which applications can run in the background~\cite{iOsDev}, despite the obvious concerns this raises for user experience.  Cloud computing providers routinely utilized their clusters at only 10\% to 50\% to keep the system responsive despite the additional operational costs of consuming electricity and the significant impact to the capital costs of the infrastructure~\cite{Barroso2009,Hennessy2011}.

Historically operating systems have not provided useful mechanisms that implement stronger performance guarantees, so developers have been left with few alternatives to over-provisioning.  Resource allocation has been rather unsystematic making it difficult to reason about the expected response time of an application.  Responsiveness has been described by a single value (usually called a \emph{priority}) associated with a thread of computation and adjusted within the operating system by a variety of ad-hoc mechanisms.   Other shared resources either employ independent machinery (\emph{e.g.,} memory, caches), or are deemed so abundant as to require no explicit management at all (\emph{e.g.,} I/O, network bandwidth).

The assumptions underlying strategies of this sort no longer hold, especially for emerging client systems.  The value of application responsiveness is highly nonlinear for an increasing variety of applications like streaming media or gaming; for these real-time applications, performance is measured as sufficient if the deadline is met and insufficient otherwise.  Priority approaches have no mechanism to understand deadlines or the resources required to meet a deadline and as such must run the highest priority applications as fast as possible on all the resources requested.   As a result, interactive and realtime applications are often run needlessly fast with significantly over-provisioned resources --wasting power and energy and preventing other applications from using the resources.  

Alternatively, by understanding and effectively adapting to application requirements, the OS can provide predictable behavior without over-provisioning, allowing excess resources to be turned off or to be used opportunistically --gaining efficiency.  In this paper, we present PACORA, a resource allocation framework for general-purpose operating systems, which is designed to provide responsiveness guarantees to a simultaneous mix of high-throughput parallel, interactive, and real-time applications in an efficient, scalable manner. PACORA leverages convex optimization and application performance models to determine the optimal amount of each resource to give each application, enabling the OS to make trade-offs between application QoS/responsiveness, system performance, and energy efficiency.  

%We will focus primarily on client systems rather than servers or data centers, but nearly all of the principles discussed here are applicable in these other domains as well.

\fix{Add Performance Numbers}


%``Resource allocation'' as the term is used here means the apportionment by an operating system of processor cores, memory pages, and various categories of  bandwidth to computations that compete for those resources.  The objective is to allocate resources so as to minimize a metric of responsiveness subject to the finite resources available.  This definition naturally establishes resource allocation as a type of constrained optimization problem.  We will focus primarily on client systems rather than servers or data centers, but nearly all of the principles discussed here are applicable in these other domains as well.
%
%Historically,resource allocation has been rather unsystematic.  Responsiveness has been described by a single value (usually called a ‚Äúpriority‚Äù) associated with a thread of computation and adjusted within the operating system by a variety of ad-hoc mechanisms.  Memory allocation has usually employed independent machinery, and other resources such as I/O or network bandwidth have been deemed so abundant as to require no explicit management at all.
%
%The assumptions underlying strategies of this sort no longer hold, especially for emerging client systems.  First, applications increasingly differ in their ability to exploit multiple processor cores and other resources, and these differences are independent of their relative responsiveness requirements.  Second, the value of application responsiveness is highly nonlinear for an increasing variety of ‚ÄúQuality-Of-Service‚Äù (QOS) applications like streaming media or gaming; for these real-time applications, responsiveness is approximately two-valued depending on whether performance is adequate or not.  Third, power and energy are key concerns, in mobile computing for example, and available battery energy itself becomes a component of responsiveness.
%
%Traditionally, predictability is obtained at a significant expense by designing for the worst- case and over-provisioning.  However, by understanding and effectively adapting to application requirements, the OS can provide predictable behavior without over-provisioning, allowing excess resources to be turned off or to be used opportunistically -- gaining efficiency.
%
%Applications increasingly differ in their ability to exploit multiple processor cores and other resources, and these differences are independent of their relative responsiveness requirements. PACORA leverages convex optimization and application performance models to determine the optimal number of resources (e.g., cores, cache slices, memory pages, various kinds of bandwidth) to give each application, enabling the OS to make trade-offs between application quality-of-service/responsiveness, system performance, and energy efficiency.