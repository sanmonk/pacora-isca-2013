\section{Introduction}

``Resource allocation'' as the term is used here means the apportionment by an operating system of processor cores, memory pages, and various categories of  bandwidth to computations that compete for those resources.  The objective is to allocate resources so as to minimize a metric of responsiveness subject to the finite resources available.  This definition naturally establishes resource allocation as a type of constrained optimization problem.  We will focus primarily on client systems rather than servers or data centers, but nearly all of the principles discussed here are applicable in these other domains as well.

Historically,resource allocation has been rather unsystematic.  Responsiveness has been described by a single value (usually called a “priority”) associated with a thread of computation and adjusted within the operating system by a variety of ad-hoc mechanisms.  Memory allocation has usually employed independent machinery, and other resources such as I/O or network bandwidth have been deemed so abundant as to require no explicit management at all.

The assumptions underlying strategies of this sort no longer hold, especially for emerging client systems.  First, applications increasingly differ in their ability to exploit multiple processor cores and other resources, and these differences are independent of their relative responsiveness requirements.  Second, the value of application responsiveness is highly nonlinear for an increasing variety of “Quality-Of-Service” (QOS) applications like streaming media or gaming; for these real-time applications, responsiveness is approximately two-valued depending on whether performance is adequate or not.  Third, power and energy are key concerns, in mobile computing for example, and available battery energy itself becomes a component of responsiveness.
