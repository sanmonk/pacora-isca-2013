\section{Introduction}




``Resource allocation'' as the term is used here means the apportionment by an operating system of processor cores, memory pages, and various categories of  bandwidth to computations that compete for those resources.  The objective is to allocate resources so as to minimize a metric of responsiveness subject to the finite resources available.  This definition naturally establishes resource allocation as a type of constrained optimization problem.  We will focus primarily on client systems rather than servers or data centers, but nearly all of the principles discussed here are applicable in these other domains as well.

Historically,resource allocation has been rather unsystematic.  Responsiveness has been described by a single value (usually called a “priority”) associated with a thread of computation and adjusted within the operating system by a variety of ad-hoc mechanisms.  Memory allocation has usually employed independent machinery, and other resources such as I/O or network bandwidth have been deemed so abundant as to require no explicit management at all.

The assumptions underlying strategies of this sort no longer hold, especially for emerging client systems.  First, applications increasingly differ in their ability to exploit multiple processor cores and other resources, and these differences are independent of their relative responsiveness requirements.  Second, the value of application responsiveness is highly nonlinear for an increasing variety of “Quality-Of-Service” (QOS) applications like streaming media or gaming; for these real-time applications, responsiveness is approximately two-valued depending on whether performance is adequate or not.  Third, power and energy are key concerns, in mobile computing for example, and available battery energy itself becomes a component of responsiveness.

Traditionally, predictability is obtained at a significant expense by designing for the worst- case and over-provisioning.  However, by understanding and effectively adapting to application requirements, the OS can provide predictable behavior without over-provisioning, allowing excess resources to be turned off or to be used opportunistically -- gaining efficiency.

Applications increasingly differ in their ability to exploit multiple processor cores and other resources, and these differences are independent of their relative responsiveness requirements. PACORA leverages convex optimization and application performance models to determine the optimal number of resources (e.g., cores, cache slices, memory pages, various kinds of bandwidth) to give each application, enabling the OS to make trade-offs between application quality-of-service/responsiveness, system performance, and energy efficiency.