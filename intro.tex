\section{Introduction}

Providing responsiveness is a growing need for all types of system,
ranging from webservers and databases running on cloud systems,
through interactive multimedia applications on mobile clients, to
emerging distributed embedded systems. Additionally, systems are
required to meet these response-time demands while improving energy
efficiency to reduce system power consumption and improve battery
life.

Ideally, applications should be given just enough system resources
(\emph{e.g.}  nodes, processor cores, cache slices, memory pages,
various kinds of bandwidth) to meet their performance requirements
consistently.  However, allocating resources among multiple parallel,
real-time applications while satisfying all of their
\emph{Quality-of-Service} (QoS) requirements is a complex optimization
problem, particularly as modern hardware diversifies to include a
variety of parallel architectures (\emph{e.g.,} multicore, GPUs).

Historically, OSes often attempted to represent performance
requirements with a single value (usually called a \emph{priority})
associated with a thread of computation and adjusted within the OS by
a variety of \emph{ad-hoc} mechanisms.  OSes have also been rather
unsystematic about resource allocation and hence have not provided
useful mechanisms to implement stronger performance guarantees among
multiple competing applications, making it difficult to reason about
the expected response time of an application.
%% Krste: Not sure what this text is talking about.  Other shared
%% resources either employ independent machinery (\emph{e.g.}  memory,
%% caches), or are deemed so abundant as to require no explicit
%% management at all (\emph{e.g.} I/O, network bandwidth).

Priority-based approaches have no mechanism to describe deadlines or
the resources required to meet them, and so must run the highest
priority applications as fast as possible on all the resources
requested.  Consequently, interactive and real-time applications are
often run needlessly fast with significant over-provisioning ---
wasting energy and reducing throughput by preventing other
applications from using the resources.  Evidence of this behavior can
be found in current systems of all sizes.  Cloud computing providers
routinely utilize their clusters at only 10\% to 50\% to keep the
system responsive, despite the significant impact on infrastructure
capital costs and the additional operational costs of consuming
electricity~\cite{Barroso2009,Hennessy2011}.  In some cases, cloud
providers run only a single application on a cluster to avoid
unexpected interference.  Some mobile systems have gone so far as to
limit which applications can run in the background~\cite{iOsDev} in
order to preserve responsiveness and battery life, despite the obvious
concerns for the overall user experience.  In the embedded space,
realtime developers often use completely separate systems for each
application to ensure QoS, despite the high cost of this approach.

In this paper, we present \pacora, a resource-allocation framework to
provide responsiveness guarantees for a simultaneous mix of parallel,
interactive, and real-time applications in an efficient, scalable
manner.  \pacora allows both application deadlines and the relative
importance of meeting these deadlines to be specified.  Unlike
traditional systems, \pacora considers \emph{all} resource types when
making decisions.  Using runtime measurements, application-specific
performance models are built and maintained to help determine the
resources required to meet each application's performance goals.  The
quantity of each resource to give each application is determined using
convex optimization, allowing the system to make continuous trade-offs
among application responsiveness, system performance, and energy
efficiency.

We believe \pacora is applicable to many resource-allocation
scenarios, from cloud providers determining how many resources to give
each job to avoid violating SLAs, through databases allocating
resources to queries, to distributed embedded systems allocating
bandwidth among devices and sensors.  In this paper we choose to study
\pacora implemented in a general-purpose operating system for client
systems, because we believe this scenario has some of the most
difficult resource allocation challenges: a constantly changing
application mix requiring low overhead and fast response times, shared
resources that create more interference among the applications, and
platforms that are too diverse to allow \emph{a priori} performance
prediction.
% applications that are more likely to be written by domain experts, thus less highly optimized.

\fix{Add Performance Numbers}

In this paper we first present the architecture of \pacora in Section~\ref{sys_design}.  In Section~\ref{eval}, we evaluate \pacora's effectiveness at resource allocation. Section~\ref{dyn_opt} describes and evaluates our dynamic penalty optimization algorithm. Sections~\ref{app_func} and~\ref{model_creation} describe response time functions and their creation in detail.  Section~\ref{discuss} some challenges and possible solutions for \pacora. Section~\ref{related_work} discusses related work, and Section~\ref{conclusion} concludes.
